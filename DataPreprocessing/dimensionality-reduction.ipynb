{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the code you need to import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data operations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to prepare a file with .csv extension from a dataset\n",
    "\n",
    "You can just skip this part and continue to the next section\n",
    "\n",
    "I just wanted to show you how I prepared/processed the available dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset from sklearn library\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "# Or you can dowload it from here: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "breast = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features \n",
    "breast_data = breast.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimensions of features\n",
    "breast_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels\n",
    "breast_labels = breast.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimensions of labels\n",
    "breast_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the labels \n",
    "labels = np.reshape(breast_labels, (569,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the features and their corresponding labels\n",
    "final_breast_data = np.concatenate([breast_data,labels], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimensions\n",
    "final_breast_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the feature names\n",
    "colnames = breast.feature_names\n",
    "print(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of it\n",
    "colnames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should add the \"label\" to the colnames\n",
    "cols = np.append(colnames,'label')\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(final_breast_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the concatenated array\n",
    "breast_dataset = pd.DataFrame(final_breast_data)\n",
    "breast_dataset.columns = cols\n",
    "\n",
    "# String operations (optional)\n",
    "breast_dataset.columns = breast_dataset.columns.str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "breast_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the binary labels to strings\n",
    "breast_dataset['label'].replace(0, 'Benign',inplace=True)\n",
    "breast_dataset['label'].replace(1, 'Malignant',inplace=True)\n",
    "breast_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe as a .csv file\n",
    "export_csv = breast_dataset.to_csv ('breast_cancer.csv', index = None, sep = \";\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<br>\n",
    "\n",
    "### Principal Component Analysis with Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Breast Cancer dataset:\n",
    "<ul>\n",
    "<li> multivariate data</li>\n",
    "<li> 2 classes: 0 ---> benign, 1 ---> malignant</li>\n",
    "<li> 212 malignant samples versus 357 benign samples</li>\n",
    "<li> 30 features (data) and their labels (targets)</li>\n",
    "<li> \"clean\" dataset</li>\n",
    "</ul>\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the content of the breast.csv file into a dataFrame\n",
    "df_breast = pd.read_csv('breast_cancer.csv', index_col = None, sep = \";\")\n",
    "df_breast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure that we see all the columns\n",
    "pd.set_option('max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the descriptive stats\n",
    "df_breast.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize some of the features and their relations using seaborn\n",
    "#sns.set(font_scale = 1)\n",
    "sns.pairplot(df_breast, vars = [\"mean_radius\", \"mean_texture\", \"mean_perimeter\", \"mean_area\", \"mean_smoothness\"], hue = \"label\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can always plot all the variables using the following line but it takes time, plus it is not easy to interpret the figure...\n",
    "\n",
    "#sns_plot = sns.pairplot(df_breast, kind='scatter', hue='label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just in case you are curious about it, I have already done that:\n",
    "\n",
    "<img src=\"sns30x30.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anyway let's go back to the stats\n",
    "df_breast.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "As you can see the features have different ranges, so what should we do? <b>Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature data (you don't need the labels because PCA is unsupervised)\n",
    "feats = df_breast.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the standard scaler tool for z-score normalization\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the values with normalized ones\n",
    "norm_feats = StandardScaler().fit_transform(feats) # normalizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the mean == 0 and std == 1\n",
    "print(\"mean = \", np.mean(norm_feats), \", std = \", np.std(norm_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dataframe to display the normalized features:\n",
    "norm_df = pd.DataFrame(norm_feats,columns=df_breast.columns[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the normalized dataframe\n",
    "norm_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the descriptive stats\n",
    "norm_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PCA from sklearn\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reduce the dimensions to 2 to better visualize it \n",
    "pca_2d = PCA(n_components = 2)\n",
    "pca_breast = pca_2d.fit_transform(norm_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to display the components\n",
    "pca_df = pd.DataFrame(data = pca_breast, columns = ['principo1', 'principo2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tail of it\n",
    "pca_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display how much the new components represent the original data\n",
    "print('Explained variation per principal component: {}'.format(pca_2d.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "\n",
    "plt.figure();\n",
    "plt.figure(figsize = (8,8));\n",
    "plt.xticks(fontsize = 12);\n",
    "plt.yticks(fontsize = 12);\n",
    "plt.xlabel('Principal Component - 1', fontsize = 14);\n",
    "plt.ylabel('Principal Component - 2', fontsize = 14);\n",
    "plt.title(\"Principal Component Analysis of Breast Cancer Dataset\", fontsize = 14);\n",
    "\n",
    "plt.scatter(pca_df.principo1, pca_df.principo2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the font size for matplotlib and seaborn libraries\n",
    "plt.rc(\"font\", size = 14)\n",
    "sns.set(font_scale = 1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting two of them together\n",
    "principo = pca_df\n",
    "principo['labels'] = df_breast.label\n",
    "sns.pairplot(pca_df, height = 4, vars = [\"principo1\", \"principo2\"], hue = \"labels\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result with class identifiers: Do not forget that our main motivation is to visualize what we have and \n",
    "# get a general understanding about the shape of it, we don't classify or cluster it (just a reminder)\n",
    "plt.figure()\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.xlabel('Principal Component - 1')\n",
    "plt.ylabel('Principal Component - 2')\n",
    "plt.title(\"Principal Component Analysis of Breast Cancer Dataset\", fontsize = 16)\n",
    "\n",
    "targets = ['Benign', 'Malignant']\n",
    "colors = ['g', 'r']\n",
    "\n",
    "for target, color in zip(targets, colors):\n",
    "    i = df_breast['label'] == target\n",
    "    plt.scatter(pca_df.loc[i, 'principo1'], pca_df.loc[i, 'principo2'], c = color)\n",
    "\n",
    "plt.legend(targets, prop = {'size': 14});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to decide the number of dimensions for reduction?\n",
    "\n",
    "dim = range(1, len(df_breast.columns))\n",
    "exp_var_ratio = np.zeros(len(dim))\n",
    "\n",
    "for i in dim: \n",
    "    pca_i = PCA(n_components = i, random_state = 1)\n",
    "    pca_x = pca_i.fit_transform(norm_feats)\n",
    "    exp_var_ratio[i-1] = pca_i.explained_variance_ratio_.sum()\n",
    "    print('Explained Variance Ratio for d = ' + str(i) + '  : ' + str(pca_i.explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize it\n",
    "\n",
    "plt.figure(figsize = (12,7))\n",
    "\n",
    "plt.plot(dim, exp_var_ratio, marker = 'o', label = 'exp var ratio')\n",
    "plt.plot(dim, np.ones(len(dim))*0.9, color = 'r', label = 'limit')\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlim([np.min(dim)-1, np.max(dim)+1])\n",
    "plt.xticks(np.arange(np.min(dim)-1, np.max(dim)+1, 1.0));\n",
    "plt.xlabel('PCA - Dimension number', labelpad = 12)\n",
    "plt.ylabel('Cumulative Sum of Explained Variance Ratio', labelpad = 12);\n",
    "plt.legend(loc = 'lower right', fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Linear Discriminant Analysis with Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris dataset contains data about 3 different species as class labels:\n",
    "<ul>\n",
    "    <li> Setosa</li>\n",
    "    <li> Versicolour</li>\n",
    "    <li> Virginica</li>\n",
    "</ul>\n",
    "And their petal and sepal lengths/widths as features.\n",
    "<img src=\"iris_petal_sepal.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset from sklearn library\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import iris data from the library and create a dataframe with it\n",
    "iris = load_iris()\n",
    "df_iris = pd.DataFrame(data = iris['data'], columns = iris['feature_names'])\n",
    "df_iris['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "df_iris.rename(columns={'sepal length (cm)':'sepal_length',\n",
    "                    'sepal width (cm)':'sepal_width',\n",
    "                    'petal length (cm)':'petal_length',\n",
    "                    'petal width (cm)':'petal_width'}, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the new column names\n",
    "df_iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset properties by classes \n",
    "labelGroups = df_iris.groupby('species')\n",
    "\n",
    "for name, group in labelGroups:\n",
    "    # print the name of the group\n",
    "    print(\"\\n\\n\", name)\n",
    "    # print data for that group\n",
    "    print(group.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the features to see their pairwise relationships \n",
    "sns.pairplot(df_iris, kind = 'scatter', hue = 'species');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the lda module from sklearn library\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data to be fed to LDA\n",
    "# First separate the features\n",
    "x = df_iris.iloc[:,0:4]\n",
    "# Then the labels, because LDA is a supervised method\n",
    "y = df_iris['species']\n",
    "\n",
    "# Let's start with 2 components\n",
    "lda = LDA(n_components=2).fit_transform(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dataset after LDA \n",
    "lda_df = pd.DataFrame({'Feature1':lda[:,0], 'Feature2':lda[:,1], 'species':df_iris['species']})\n",
    "lda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the reduced features\n",
    "sns.pairplot(lda_df, kind = 'scatter', hue = 'species');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to decide the number of dimensions for reduction?\n",
    "\n",
    "dim = range(1, len(df_iris.columns))\n",
    "exp_var_ratio = np.zeros(len(dim))\n",
    "\n",
    "for i in dim: \n",
    "    lda_i = LDA(n_components = i)\n",
    "    lda_x = lda_i.fit_transform(x,y)\n",
    "    exp_var_ratio[i-1] = lda_i.explained_variance_ratio_.sum()\n",
    "    print('Explained Variance Ratio for d = ' + str(i) + '  : ' + str(lda_i.explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Extra exercises: \n",
    "\n",
    "- We didn't perform any normalization on the iris dataset, what would we have if we had normalized it before LDA?\n",
    "- Feed the iris dataset to PCA and compare it with the LDA results.\n",
    "- Let's go back to the breast cancer dataset and PCA, what would we have if we didn't normalize it? The normalization, does it have any effect on the PCA performed in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it's your turn\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
