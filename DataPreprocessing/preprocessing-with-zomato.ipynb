{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Practice with Zomato Dataset\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the numpy and pandas libraries with alias 'np' and 'pd' into your namespace \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# and import only pyplot from matplotlib library as 'plt' into your namespace\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import the content of a .csv file into a dataFrame\n",
    "df = pd.read_csv('zomato_kisa.csv', index_col = None, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 entries\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just some modifications to ease our acces to dataframe columns\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a quick statistic summary of your data (based on quantitative features)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a quick statistic summary of your data (based on qualitative features)\n",
    "df.describe(include = \"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict the number of rows to display\n",
    "pd.set_option('max_rows', 10)\n",
    "#pd.reset_option('max_rows')   # you can always reset it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of \"cuisines\" is 95, let's check the feature\n",
    "df.cuisines\n",
    "\n",
    "# or \n",
    "#df.cuisines.tail(20)   # (just because I know the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proper way to check it: If there is NaN, it returns True\n",
    "\n",
    "df.cuisines.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proper way to check it: If there is NaN, it returns True\n",
    "# When you add any(), if there is at least one True, then it returns True\n",
    "df.cuisines.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One solution is to drop the column with the NaN entries \n",
    "df_dropcol = df.dropna(axis='columns')\n",
    "df_dropcol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another solution is to drop the rows with the NaN entries\n",
    "df_droprow = df.dropna(axis='rows')\n",
    "df_droprow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or \n",
    "# First, let's check the rows with NaN entries\n",
    "df[df.cuisines.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can always fill them manually using their index\n",
    "df.iloc[84,9] = \"American\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check visually if the index = 84 is replaced\n",
    "pd.reset_option('max_rows')\n",
    "df.cuisines.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can use fillna() method\n",
    "df.cuisines.fillna(\"American\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the new values of NaN \n",
    "df.cuisines.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Redundancy check\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any redundancy (if there is any duplicated entry it returns True)\n",
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b> Dataset Mess-up\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we copy our dataset\n",
    "df_copy = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a new quantitative feature: \"revenue\" to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First generate a numpy array and fill it randomly\n",
    "rev = np.random.randint(10,1000, size = len(df_copy))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for \"revenue\" in df_copy\n",
    "df_copy['revenue'] = rev\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let's add some NaN values in the following columns: \n",
    "<ul>\n",
    "<li>\"revenue\"</li>\n",
    "<li>\"rating_color\"</li>\n",
    "<li>\"rating_text\"</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random indexes for \"revenue\" feature\n",
    "ind_revenue = np.random.randint(len(df_copy), size = 5)\n",
    "print(type(ind_revenue), ind_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random indexes for \"rating_color\" feature\n",
    "ind_color = np.random.randint(len(df_copy), size = 5)\n",
    "print(ind_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random indexes for \"rating_text\" feature\n",
    "ind_text = np.random.randint(len(df_copy), size = 5)\n",
    "print(ind_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill them with NaN values in df_copy\n",
    "for i in range(len(ind_revenue)):\n",
    "    df_copy.loc[ind_revenue[i], 'revenue'] = np.nan\n",
    "    df_copy.loc[ind_color[i], 'rating_color'] = np.nan\n",
    "    df_copy.loc[ind_text[i], 'rating_text'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the modifications\n",
    "df_copy.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Decision to make: Drop them or replace/fill in the values?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# List the rows with NaN values for \"revenue\"\n",
    "df_copy[df_copy.revenue.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the descriptive stats\n",
    "df_copy.revenue.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and its mode\n",
    "df_copy.revenue.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anatomy of type conversion :)\n",
    "r_mean = df_copy.revenue.mean()\n",
    "r_mean_rounded_up = np.around(df_copy.revenue.mean())\n",
    "r_int = int(r_mean_rounded_up)  # ----> Type conversion\n",
    "print(r_int)\n",
    "\n",
    "# Or in a single line\n",
    "#print(int(np.around(df_copy.revenue.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the NaN values with mean, median, mode, etc\n",
    "df_copy.revenue.fillna(int(np.around(df_copy.revenue.mean())), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check if everything is OK\n",
    "df_copy.loc[ind_revenue, ['restaurant_id','restaurant_name','revenue']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let's look at the qualitative features \"rating_color\" and \"rating_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the rows with NaN values for \"rating_color\"\n",
    "df_copy[df_copy.rating_color.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the rows with NaN values for \"rating_text\"\n",
    "df_copy[df_copy.rating_text.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "If we look closely, we can that there is a rule-based relationship between the following columns:\n",
    "<ul>\n",
    "<li>\"aggregate_rating\"</li>\n",
    "<li>\"rating_color\"</li>\n",
    "<li>\"rating_text\"</li>\n",
    "</ul>\n",
    "\n",
    "Such as: \n",
    "\n",
    "> 0.0 ---> White ---> Not Rated\n",
    "\n",
    "> 1.5 ---> Red ---> Poor\n",
    "\n",
    "> 2.5 ---> Orange ---> Average\n",
    "\n",
    "> 3.5 ---> Yellow ---> Good\n",
    "\n",
    "> 4.0 ---> Green ----> Very Good\n",
    "\n",
    "> 4.5 ---> Dark Green ---> Excellent\n",
    "\n",
    "Then let's fill in the NaN values using a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0 -----> White ------> Not Rated\n",
    "# 1.5 -----> Red --------> Poor\n",
    "# 2.5 -----> Orange -----> Average\n",
    "# 3.5 -----> Yellow -----> Good\n",
    "# 4.0 -----> Green ------> Very Good\n",
    "# 4.5 ---> Dark Green ---> Excellent\n",
    "\n",
    "for i in range(len(df_copy.aggregate_rating)):\n",
    "    if (pd.isna(df_copy.loc[i,'rating_color']) or pd.isna(df_copy.loc[i,'rating_text'])):\n",
    "        if (df_copy.loc[i,'aggregate_rating'] == 0):\n",
    "            df_copy.loc[i,'rating_color'] = \"White\"\n",
    "            df_copy.loc[i,'rating_text'] = \"Not Rated\"\n",
    "        elif (df_copy.loc[i,'aggregate_rating'] >= 1.5 and df_copy.loc[i,'aggregate_rating'] < 2.5):\n",
    "            df_copy.loc[i,'rating_color'] = \"Red\"\n",
    "            df_copy.loc[i,'rating_text'] = \"Poor\"\n",
    "        elif (df_copy.loc[i,'aggregate_rating'] >= 2.5 and df_copy.loc[i,'aggregate_rating'] < 3.5):\n",
    "            df_copy.loc[i,'rating_color'] = \"Orange\"\n",
    "            df_copy.loc[i,'rating_text'] = \"Average\"\n",
    "        elif (df_copy.loc[i,'aggregate_rating'] >= 3.5 and df_copy.loc[i,'aggregate_rating'] < 4):\n",
    "            df_copy.loc[i,'rating_color'] = \"Yellow\"\n",
    "            df_copy.loc[i,'rating_text'] = \"Good\"\n",
    "        elif (df_copy.loc[i,'aggregate_rating'] >= 4 and df_copy.loc[i,'aggregate_rating'] < 4.5):\n",
    "            df_copy.loc[i,'rating_color'] = \"Green\"\n",
    "            df_copy.loc[i,'rating_text'] = \"Very Good\"\n",
    "        elif (df_copy.loc[i,'aggregate_rating'] >= 4.5):\n",
    "            df_copy.loc[i,'rating_color'] = \"Dark Green\"\n",
    "            df_copy.loc[i,'rating_text'] = \"Excellent\"\n",
    "        else:\n",
    "            df_copy.loc[i,'rating_color'] = \"None\"\n",
    "            df_copy.loc[i,'rating_text'] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to check the values, you can display them\n",
    "df_copy.loc[ind_color, ['aggregate_rating','rating_color','rating_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a final check\n",
    "df_copy.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, it's your turn, you can re-do all the things above with the full zomato dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
